{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNxOkyNm1BF9DZ/WYV6E87v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c8b10f94c380471cb70fd733656bf4ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cafe486c900e465981eb6800ed2a2f80",
              "IPY_MODEL_039fc52147c6495fa16dd17cdd9e3ff6",
              "IPY_MODEL_f2c4baed3ad8495fa216e1e0e3a3a11c"
            ],
            "layout": "IPY_MODEL_8b1fdcad257947b8afcfec063d8795b6"
          }
        },
        "cafe486c900e465981eb6800ed2a2f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_211ec76859c04ceaa2c5d66bd6a07292",
            "placeholder": "​",
            "style": "IPY_MODEL_e89f9ae8c6df4267a5e611ab10b58d4e",
            "value": "model.safetensors: 100%"
          }
        },
        "039fc52147c6495fa16dd17cdd9e3ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d9f4ff8f98442c3a8ed949011584973",
            "max": 468313032,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cbc3354d00774cda818d7733dc208f63",
            "value": 468313032
          }
        },
        "f2c4baed3ad8495fa216e1e0e3a3a11c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6205e3cf8914754bdd98f63d1370f22",
            "placeholder": "​",
            "style": "IPY_MODEL_ddd2dfc31ab94fdcbc2e01aa55d16906",
            "value": " 468M/468M [00:07&lt;00:00, 75.6MB/s]"
          }
        },
        "8b1fdcad257947b8afcfec063d8795b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "211ec76859c04ceaa2c5d66bd6a07292": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e89f9ae8c6df4267a5e611ab10b58d4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d9f4ff8f98442c3a8ed949011584973": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbc3354d00774cda818d7733dc208f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6205e3cf8914754bdd98f63d1370f22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddd2dfc31ab94fdcbc2e01aa55d16906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "066f413f0921492789332590d49a586b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_241e625e34b74ccfa0281f2fbfef47f2",
              "IPY_MODEL_c747375d6ed948298594660ddaab5d12",
              "IPY_MODEL_fdb350396857455e9c948a4f977e360c"
            ],
            "layout": "IPY_MODEL_e54c7fee55fe400c9fec24ba291b9411"
          }
        },
        "241e625e34b74ccfa0281f2fbfef47f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cd3f37adb68488b8358ee3933f4e7e4",
            "placeholder": "​",
            "style": "IPY_MODEL_b2e9f627d237435aba118f92d087b1e7",
            "value": "Map: 100%"
          }
        },
        "c747375d6ed948298594660ddaab5d12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77a595a4d6694bacae978788fec9a079",
            "max": 124673,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af1da054cd0e4a5ba22442f99091650d",
            "value": 124673
          }
        },
        "fdb350396857455e9c948a4f977e360c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_176354e4053240009dfa226d748f036c",
            "placeholder": "​",
            "style": "IPY_MODEL_d68c040bd7244e9a8148dc4a91d1f892",
            "value": " 124673/124673 [01:07&lt;00:00, 2663.22 examples/s]"
          }
        },
        "e54c7fee55fe400c9fec24ba291b9411": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cd3f37adb68488b8358ee3933f4e7e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2e9f627d237435aba118f92d087b1e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77a595a4d6694bacae978788fec9a079": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af1da054cd0e4a5ba22442f99091650d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "176354e4053240009dfa226d748f036c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d68c040bd7244e9a8148dc4a91d1f892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae7e42a8c5364bb29d9f0624822b37fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0f5618659cc4e38ad1a713d36f4fddd",
              "IPY_MODEL_5deed2076c064ad6b71489a7191fb925",
              "IPY_MODEL_e629d1f7571b44cdbc295cc848dc4651"
            ],
            "layout": "IPY_MODEL_ef8f354fc6934c23af4d9fbdd1373f94"
          }
        },
        "d0f5618659cc4e38ad1a713d36f4fddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5da4eab5d7d47d3b31edac2276864ca",
            "placeholder": "​",
            "style": "IPY_MODEL_4184da0298b5455bb5a86749def24125",
            "value": "Map: 100%"
          }
        },
        "5deed2076c064ad6b71489a7191fb925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f40009e63ed4205842fb9f6df667fc8",
            "max": 6562,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8068c609ba6c4b5c8abb986f0f636eec",
            "value": 6562
          }
        },
        "e629d1f7571b44cdbc295cc848dc4651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf0a1936090c40eb83a9495d0f1a63a5",
            "placeholder": "​",
            "style": "IPY_MODEL_9930f67fa3a34443becbd75966ed5eca",
            "value": " 6562/6562 [00:01&lt;00:00, 6005.98 examples/s]"
          }
        },
        "ef8f354fc6934c23af4d9fbdd1373f94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5da4eab5d7d47d3b31edac2276864ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4184da0298b5455bb5a86749def24125": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f40009e63ed4205842fb9f6df667fc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8068c609ba6c4b5c8abb986f0f636eec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf0a1936090c40eb83a9495d0f1a63a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9930f67fa3a34443becbd75966ed5eca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "033eff09486943e2a71ce38ddd209dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4829ed9e92704f6798371ef938fac297",
              "IPY_MODEL_516337ee49b6452e9cf1bb2f94611df3",
              "IPY_MODEL_93f1c9a660444d1aac78c990a22901a8"
            ],
            "layout": "IPY_MODEL_7b12077c1b8e470d81265249e47be217"
          }
        },
        "4829ed9e92704f6798371ef938fac297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8ece82ed10e484197ede494cd341b7f",
            "placeholder": "​",
            "style": "IPY_MODEL_c2d00395f24042ad870f08e810b39458",
            "value": "Fetching 12 files: 100%"
          }
        },
        "516337ee49b6452e9cf1bb2f94611df3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15056df7d1f0483ca86d12ac97dac931",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b59f7fb16fef436ca150d31de5302cfc",
            "value": 12
          }
        },
        "93f1c9a660444d1aac78c990a22901a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5d93ef281414ad3a0bc05ce56cd3509",
            "placeholder": "​",
            "style": "IPY_MODEL_b9ceb36ecb5e41b19fc8ca9ed6258f32",
            "value": " 12/12 [00:00&lt;00:00, 931.26it/s]"
          }
        },
        "7b12077c1b8e470d81265249e47be217": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8ece82ed10e484197ede494cd341b7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2d00395f24042ad870f08e810b39458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15056df7d1f0483ca86d12ac97dac931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b59f7fb16fef436ca150d31de5302cfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5d93ef281414ad3a0bc05ce56cd3509": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9ceb36ecb5e41b19fc8ca9ed6258f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MonicaCushy/CDSS/blob/main/MycoPromoter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: 重启后第一个运行 - 预先修补文件\n",
        "import os\n",
        "\n",
        "# 先挂载Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 安装依赖\n",
        "!pip install transformers datasets accelerate einops -q\n",
        "\n",
        "# 下载模型（但不加载到内存）\n",
        "print(\"📥 下载模型文件...\")\n",
        "!python -c \"from huggingface_hub import snapshot_download; snapshot_download('zhihan1996/DNABERT-2-117M')\"\n",
        "\n",
        "# 找到文件路径\n",
        "import subprocess\n",
        "result = subprocess.run(['find', '/root/.cache', '-name', 'flash_attn_triton.py'], capture_output=True, text=True)\n",
        "flash_files = [p.strip() for p in result.stdout.strip().split('\\n') if p.strip()]\n",
        "result = subprocess.run(['find', '/root/.cache', '-name', 'bert_layers.py'], capture_output=True, text=True)\n",
        "bert_files = [p.strip() for p in result.stdout.strip().split('\\n') if p.strip()]\n",
        "\n",
        "print(f\"找到 flash_attn_triton.py: {flash_files}\")\n",
        "print(f\"找到 bert_layers.py: {bert_files}\")\n",
        "\n",
        "# 用纯PyTorch实现替换flash_attn_triton.py\n",
        "fake_flash_attn = '''\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "def flash_attn_qkvpacked_func(qkv, bias=None, dropout_p=0.0, softmax_scale=None, causal=False, *args, **kwargs):\n",
        "    batch, seqlen, three, nheads, headdim = qkv.shape\n",
        "    q, k, v = qkv.unbind(dim=2)\n",
        "    q, k, v = q.transpose(1,2), k.transpose(1,2), v.transpose(1,2)\n",
        "    scale = softmax_scale or (1.0 / math.sqrt(headdim))\n",
        "    attn = torch.matmul(q, k.transpose(-2,-1)) * scale\n",
        "    if bias is not None: attn = attn + bias\n",
        "    if causal:\n",
        "        mask = torch.triu(torch.ones(seqlen, seqlen, device=qkv.device, dtype=torch.bool), diagonal=1)\n",
        "        attn = attn.masked_fill(mask, float('-inf'))\n",
        "    attn = F.softmax(attn, dim=-1, dtype=torch.float32).to(qkv.dtype)\n",
        "    if dropout_p > 0 and torch.is_grad_enabled(): attn = F.dropout(attn, p=dropout_p)\n",
        "    return torch.matmul(attn, v).transpose(1,2)\n",
        "\n",
        "flash_attn_func = flash_attn_qkvpacked_func\n",
        "flash_attn_kvpacked_func = flash_attn_qkvpacked_func\n",
        "'''\n",
        "\n",
        "for f in flash_files:\n",
        "    print(f\"✏️ 替换: {f}\")\n",
        "    with open(f, 'w') as fp:\n",
        "        fp.write(fake_flash_attn)\n",
        "\n",
        "print(\"✅ 修补完成！现在可以安全加载模型了\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfj0rvgRAGTt",
        "outputId": "b86299f3-5448-467a-9826-4e4b746e34ae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "📥 下载模型文件...\n",
            "Fetching 12 files:   0% 0/12 [00:00<?, ?it/s]\n",
            "bert_layers.py: 40.7kB [00:00, 69.0MB/s]\n",
            "\n",
            "configuration_bert.py: 1.01kB [00:00, 6.59MB/s]\n",
            "\n",
            "README.md: 1.32kB [00:00, 8.69MB/s]\n",
            "\n",
            "config.json: 100% 904/904 [00:00<00:00, 356kB/s]\n",
            "\n",
            ".gitattributes: 1.52kB [00:00, 9.74MB/s]\n",
            "Fetching 12 files:   8% 1/12 [00:00<00:03,  3.05it/s]\n",
            "flash_attn_triton.py: 42.7kB [00:00, 77.4MB/s]\n",
            "\n",
            "bert_padding.py: 6.10kB [00:00, 26.3MB/s]\n",
            "\n",
            "LICENSE: 11.4kB [00:00, 41.7MB/s]\n",
            "\n",
            "generation_config.json: 100% 90.0/90.0 [00:00<00:00, 691kB/s]\n",
            "Fetching 12 files:  75% 9/12 [00:00<00:00, 17.33it/s]\n",
            "tokenizer_config.json: 100% 158/158 [00:00<00:00, 1.24MB/s]\n",
            "\n",
            "tokenizer.json: 168kB [00:00, 37.3MB/s]\n",
            "\n",
            "pytorch_model.bin:   0% 0.00/468M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model.bin:  14% 66.0M/468M [00:02<00:14, 28.0MB/s]\u001b[A\n",
            "pytorch_model.bin:  28% 133M/468M [00:02<00:05, 59.2MB/s] \u001b[A\n",
            "pytorch_model.bin:  43% 200M/468M [00:02<00:02, 97.0MB/s]\u001b[A\n",
            "pytorch_model.bin:  57% 267M/468M [00:03<00:02, 90.3MB/s]\u001b[A\n",
            "pytorch_model.bin:  71% 334M/468M [00:03<00:01, 127MB/s] \u001b[A\n",
            "pytorch_model.bin:  86% 401M/468M [00:03<00:00, 168MB/s]\u001b[A\n",
            "pytorch_model.bin: 100% 468M/468M [00:06<00:00, 76.3MB/s]\n",
            "Fetching 12 files: 100% 12/12 [00:07<00:00,  1.71it/s]\n",
            "找到 flash_attn_triton.py: ['/root/.cache/huggingface/hub/models--zhihan1996--DNABERT-2-117M/snapshots/7bce263b15377fc15361f52cfab88f8b586abda0/flash_attn_triton.py']\n",
            "找到 bert_layers.py: ['/root/.cache/huggingface/hub/models--zhihan1996--DNABERT-2-117M/snapshots/7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py']\n",
            "✏️ 替换: /root/.cache/huggingface/hub/models--zhihan1996--DNABERT-2-117M/snapshots/7bce263b15377fc15361f52cfab88f8b586abda0/flash_attn_triton.py\n",
            "✅ 修补完成！现在可以安全加载模型了\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: 加载并测试（自动检测设备）\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"🖥️ 使用设备: {device}\")\n",
        "\n",
        "if device == \"cpu\":\n",
        "    print(\"⚠️ GPU未启用！请点击 Runtime → Change runtime type → 选择 T4 GPU\")\n",
        "else:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
        "    model = AutoModel.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True).to(device)\n",
        "\n",
        "    inputs = tokenizer(\"ACGTACGTACGT\", return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        out = model(**inputs)\n",
        "    print(f\"✅ 成功！Shape: {out.last_hidden_state.shape}\")"
      ],
      "metadata": {
        "id": "FjZUk1WxARMo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532,
          "referenced_widgets": [
            "c8b10f94c380471cb70fd733656bf4ec",
            "cafe486c900e465981eb6800ed2a2f80",
            "039fc52147c6495fa16dd17cdd9e3ff6",
            "f2c4baed3ad8495fa216e1e0e3a3a11c",
            "8b1fdcad257947b8afcfec063d8795b6",
            "211ec76859c04ceaa2c5d66bd6a07292",
            "e89f9ae8c6df4267a5e611ab10b58d4e",
            "3d9f4ff8f98442c3a8ed949011584973",
            "cbc3354d00774cda818d7733dc208f63",
            "e6205e3cf8914754bdd98f63d1370f22",
            "ddd2dfc31ab94fdcbc2e01aa55d16906"
          ]
        },
        "outputId": "665d48f7-9d46-40ed-f977-bcca3ae91327"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🖥️ 使用设备: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "A new version of the following files was downloaded from https://huggingface.co/zhihan1996/DNABERT-2-117M:\n",
            "- flash_attn_triton.py\n",
            "- bert_padding.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "Some weights of BertModel were not initialized from the model checkpoint at zhihan1996/DNABERT-2-117M and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/468M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8b10f94c380471cb70fd733656bf4ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'tuple' object has no attribute 'last_hidden_state'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3213238521.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"✅ 成功！Shape: {out.last_hidden_state.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'last_hidden_state'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: 确认成功\n",
        "print(f\"✅ 模型加载成功！\")\n",
        "print(f\"输出类型: {type(out)}\")\n",
        "print(f\"输出长度: {len(out)}\")\n",
        "print(f\"Hidden states shape: {out[0].shape}\")\n",
        "\n",
        "# 这就是我们需要的embedding\n",
        "print(f\"\\n🎉 DNABERT-2 已经可以正常工作了！\")"
      ],
      "metadata": {
        "id": "9n7as7BDAmkW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77b5513a-5025-4d57-8f8e-617e5a2e161f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 模型加载成功！\n",
            "输出类型: <class 'tuple'>\n",
            "输出长度: 2\n",
            "Hidden states shape: torch.Size([1, 7, 768])\n",
            "\n",
            "🎉 DNABERT-2 已经可以正常工作了！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: 检查数据文件\n",
        "import os\n",
        "\n",
        "# 检查可能的路径\n",
        "paths_to_check = [\n",
        "    \"/content/drive/MyDrive/MycoPromoter/pretrain_corpus.txt\",\n",
        "    \"/content/drive/MyDrive/pretrain_corpus.txt\",\n",
        "]\n",
        "\n",
        "for p in paths_to_check:\n",
        "    if os.path.exists(p):\n",
        "        with open(p, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "        print(f\"✅ 找到: {p}\")\n",
        "        print(f\"   序列数量: {len(lines)}\")\n",
        "        print(f\"   示例: {lines[0][:50].strip()}...\")\n",
        "        DATA_PATH = p\n",
        "        break\n",
        "else:\n",
        "    print(\"❌ 没找到数据文件\")\n",
        "    print(\"\\n请运行这个命令查看你的Drive内容:\")\n",
        "    print(\"!ls -la '/content/drive/MyDrive/'\")"
      ],
      "metadata": {
        "id": "mK-R8zvXAztP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfc95cc4-05f9-404f-eead-fdcafeff4875"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 找到: /content/drive/MyDrive/MycoPromoter/pretrain_corpus.txt\n",
            "   序列数量: 131235\n",
            "   示例: CTTCACCACAGTGTGGAACGCGGTCGTCTCCGAACTTAACGGCGACCCTA...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: MLM预训练完整代码\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForMaskedLM,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "from datasets import Dataset\n",
        "\n",
        "# ==================== 配置 ====================\n",
        "DATA_PATH = \"/content/drive/MyDrive/MycoPromoter/pretrain_corpus.txt\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/MycoPromoter/dnabert2_mycobacterium\"\n",
        "\n",
        "BLOCK_SIZE = 128        # 序列长度\n",
        "MLM_PROB = 0.15         # 掩码比例 (教授要求)\n",
        "BATCH_SIZE = 32         # T4可以handle\n",
        "EPOCHS = 3              # 先跑3轮看效果\n",
        "LR = 5e-5               # 学习率\n",
        "\n",
        "# ==================== 加载数据 ====================\n",
        "print(\"📊 加载数据...\")\n",
        "with open(DATA_PATH, 'r') as f:\n",
        "    sequences = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "print(f\"   总序列数: {len(sequences)}\")\n",
        "\n",
        "# 创建dataset\n",
        "dataset = Dataset.from_dict({\"text\": sequences})\n",
        "dataset = dataset.train_test_split(test_size=0.05, seed=42)\n",
        "print(f\"   训练集: {len(dataset['train'])}, 验证集: {len(dataset['test'])}\")\n",
        "\n",
        "# ==================== Tokenize ====================\n",
        "print(\"\\n🔤 Tokenizing...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
        "\n",
        "def tokenize_fn(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        max_length=BLOCK_SIZE,\n",
        "        padding=\"max_length\",\n",
        "        return_special_tokens_mask=True\n",
        "    )\n",
        "\n",
        "tokenized = dataset.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
        "print(f\"   ✅ Tokenization完成\")\n",
        "\n",
        "# ==================== 加载模型 ====================\n",
        "print(\"\\n🤖 加载模型...\")\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
        "model = model.cuda()\n",
        "print(f\"   参数量: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "# ==================== 数据整理器 ====================\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=True,\n",
        "    mlm_probability=MLM_PROB\n",
        ")\n",
        "\n",
        "# ==================== 训练配置 ====================\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    overwrite_output_dir=True,\n",
        "\n",
        "    num_train_epochs=EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "\n",
        "    learning_rate=LR,\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.1,\n",
        "\n",
        "    fp16=True,\n",
        "\n",
        "    logging_steps=100,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=500,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "\n",
        "    report_to=\"none\",\n",
        "\n",
        "    # 修复：禁用safetensors格式\n",
        "    save_safetensors=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"test\"],\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "print(\"🚀 继续训练...\")\n",
        "trainer.train()\n",
        "\n",
        "# 保存最终模型\n",
        "print(\"\\n💾 保存模型...\")\n",
        "model.save_pretrained(f\"{OUTPUT_DIR}/final\", safe_serialization=False)\n",
        "tokenizer.save_pretrained(f\"{OUTPUT_DIR}/final\")\n",
        "print(f\"✅ 已保存到: {OUTPUT_DIR}/final\")"
      ],
      "metadata": {
        "id": "rlnE0NOPBDln",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "066f413f0921492789332590d49a586b",
            "241e625e34b74ccfa0281f2fbfef47f2",
            "c747375d6ed948298594660ddaab5d12",
            "fdb350396857455e9c948a4f977e360c",
            "e54c7fee55fe400c9fec24ba291b9411",
            "9cd3f37adb68488b8358ee3933f4e7e4",
            "b2e9f627d237435aba118f92d087b1e7",
            "77a595a4d6694bacae978788fec9a079",
            "af1da054cd0e4a5ba22442f99091650d",
            "176354e4053240009dfa226d748f036c",
            "d68c040bd7244e9a8148dc4a91d1f892",
            "ae7e42a8c5364bb29d9f0624822b37fd",
            "d0f5618659cc4e38ad1a713d36f4fddd",
            "5deed2076c064ad6b71489a7191fb925",
            "e629d1f7571b44cdbc295cc848dc4651",
            "ef8f354fc6934c23af4d9fbdd1373f94",
            "c5da4eab5d7d47d3b31edac2276864ca",
            "4184da0298b5455bb5a86749def24125",
            "9f40009e63ed4205842fb9f6df667fc8",
            "8068c609ba6c4b5c8abb986f0f636eec",
            "cf0a1936090c40eb83a9495d0f1a63a5",
            "9930f67fa3a34443becbd75966ed5eca"
          ]
        },
        "outputId": "05451084-b504-45dd-f7fa-1bd486eb9f5c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 加载数据...\n",
            "   总序列数: 131235\n",
            "   训练集: 124673, 验证集: 6562\n",
            "\n",
            "🔤 Tokenizing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/124673 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "066f413f0921492789332590d49a586b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/6562 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae7e42a8c5364bb29d9f0624822b37fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Tokenization完成\n",
            "\n",
            "🤖 加载模型...\n",
            "   参数量: 117,074,176\n",
            "🚀 继续训练...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11691' max='11691' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11691/11691 41:42, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>4.705000</td>\n",
              "      <td>4.647661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>4.662800</td>\n",
              "      <td>4.641298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>4.638700</td>\n",
              "      <td>4.610360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>4.625900</td>\n",
              "      <td>4.604293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>4.589500</td>\n",
              "      <td>4.593082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>4.625700</td>\n",
              "      <td>4.580919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>4.589600</td>\n",
              "      <td>4.559543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>4.586700</td>\n",
              "      <td>4.570495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>4.616800</td>\n",
              "      <td>4.538735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>4.583600</td>\n",
              "      <td>4.518477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>4.560800</td>\n",
              "      <td>4.516675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>4.526200</td>\n",
              "      <td>4.520596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>4.522800</td>\n",
              "      <td>4.489928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>4.537800</td>\n",
              "      <td>4.483229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>4.493600</td>\n",
              "      <td>4.474737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>4.532900</td>\n",
              "      <td>4.464147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>4.474600</td>\n",
              "      <td>4.461433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>4.471700</td>\n",
              "      <td>4.448893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>4.444700</td>\n",
              "      <td>4.435487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>4.438900</td>\n",
              "      <td>4.426908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>4.423600</td>\n",
              "      <td>4.395020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>4.450100</td>\n",
              "      <td>4.406439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>4.434300</td>\n",
              "      <td>4.412386</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "💾 保存模型...\n",
            "✅ 已保存到: /content/drive/MyDrive/MycoPromoter/dnabert2_mycobacterium/final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: 恢复环境 + 加载训练好的模型\n",
        "\n",
        "# 挂载Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 安装依赖\n",
        "!pip install transformers datasets accelerate einops -q\n",
        "\n",
        "# 检查模型文件是否存在\n",
        "import os\n",
        "MODEL_PATH = \"/content/drive/MyDrive/MycoPromoter/dnabert2_mycobacterium/final\"\n",
        "\n",
        "print(\"📁 检查保存的文件:\")\n",
        "if os.path.exists(MODEL_PATH):\n",
        "    for f in os.listdir(MODEL_PATH):\n",
        "        size = os.path.getsize(f\"{MODEL_PATH}/{f}\") / 1024 / 1024\n",
        "        print(f\"  ✅ {f} ({size:.1f} MB)\")\n",
        "else:\n",
        "    print(\"❌ 模型文件夹不存在！\")"
      ],
      "metadata": {
        "id": "6D4LjKqb7fqf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "823ef673-ab19-4b88-9f5d-64be1bc7a0ca"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "📁 检查保存的文件:\n",
            "  ✅ configuration_bert.py (0.0 MB)\n",
            "  ✅ config.json (0.0 MB)\n",
            "  ✅ generation_config.json (0.0 MB)\n",
            "  ✅ pytorch_model.bin (446.6 MB)\n",
            "  ✅ tokenizer_config.json (0.0 MB)\n",
            "  ✅ special_tokens_map.json (0.0 MB)\n",
            "  ✅ tokenizer.json (0.3 MB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: 修补Flash Attention + 加载模型\n",
        "\n",
        "# Step 1: 下载并修补DNABERT-2的依赖文件\n",
        "print(\"🔧 修补Flash Attention...\")\n",
        "from huggingface_hub import snapshot_download\n",
        "snapshot_download('zhihan1996/DNABERT-2-117M')\n",
        "\n",
        "import subprocess\n",
        "result = subprocess.run(['find', '/root/.cache', '-name', 'flash_attn_triton.py'], capture_output=True, text=True)\n",
        "flash_files = [p.strip() for p in result.stdout.strip().split('\\n') if p.strip()]\n",
        "\n",
        "fake_flash_attn = '''\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "def flash_attn_qkvpacked_func(qkv, bias=None, dropout_p=0.0, softmax_scale=None, causal=False, *args, **kwargs):\n",
        "    batch, seqlen, three, nheads, headdim = qkv.shape\n",
        "    q, k, v = qkv.unbind(dim=2)\n",
        "    q, k, v = q.transpose(1,2), k.transpose(1,2), v.transpose(1,2)\n",
        "    scale = softmax_scale or (1.0 / math.sqrt(headdim))\n",
        "    attn = torch.matmul(q, k.transpose(-2,-1)) * scale\n",
        "    if bias is not None: attn = attn + bias\n",
        "    if causal:\n",
        "        mask = torch.triu(torch.ones(seqlen, seqlen, device=qkv.device, dtype=torch.bool), diagonal=1)\n",
        "        attn = attn.masked_fill(mask, float('-inf'))\n",
        "    attn = F.softmax(attn, dim=-1, dtype=torch.float32).to(qkv.dtype)\n",
        "    if dropout_p > 0 and torch.is_grad_enabled(): attn = F.dropout(attn, p=dropout_p)\n",
        "    return torch.matmul(attn, v).transpose(1,2)\n",
        "\n",
        "flash_attn_func = flash_attn_qkvpacked_func\n",
        "flash_attn_kvpacked_func = flash_attn_qkvpacked_func\n",
        "'''\n",
        "\n",
        "for f in flash_files:\n",
        "    with open(f, 'w') as fp:\n",
        "        fp.write(fake_flash_attn)\n",
        "    print(f\"  ✅ 修补: {f}\")\n",
        "\n",
        "# Step 2: 加载模型\n",
        "print(\"\\n🤖 加载训练好的模型...\")\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/MycoPromoter/dnabert2_mycobacterium/final\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
        "\n",
        "# 加载你训练的权重\n",
        "state_dict = torch.load(f\"{MODEL_PATH}/pytorch_model.bin\", weights_only=False)\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(f\"✅ 模型加载成功！设备: {device}\")\n",
        "\n",
        "# Step 3: 快速测试\n",
        "test_seq = \"ACGTACGT\"\n",
        "inputs = tokenizer(test_seq, return_tensors=\"pt\").to(device)\n",
        "with torch.no_grad():\n",
        "    out = model(**inputs)\n",
        "print(f\"✅ 前向传播测试通过！输出shape: {out.logits.shape}\")"
      ],
      "metadata": {
        "id": "82pY24qh71IT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204,
          "referenced_widgets": [
            "033eff09486943e2a71ce38ddd209dc5",
            "4829ed9e92704f6798371ef938fac297",
            "516337ee49b6452e9cf1bb2f94611df3",
            "93f1c9a660444d1aac78c990a22901a8",
            "7b12077c1b8e470d81265249e47be217",
            "c8ece82ed10e484197ede494cd341b7f",
            "c2d00395f24042ad870f08e810b39458",
            "15056df7d1f0483ca86d12ac97dac931",
            "b59f7fb16fef436ca150d31de5302cfc",
            "c5d93ef281414ad3a0bc05ce56cd3509",
            "b9ceb36ecb5e41b19fc8ca9ed6258f32"
          ]
        },
        "outputId": "fdbcb925-dbdf-4ce5-a273-552a8c896626"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 修补Flash Attention...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "033eff09486943e2a71ce38ddd209dc5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ 修补: /root/.cache/huggingface/hub/models--zhihan1996--DNABERT-2-117M/snapshots/7bce263b15377fc15361f52cfab88f8b586abda0/flash_attn_triton.py\n",
            "  ✅ 修补: /root/.cache/huggingface/modules/transformers_modules/zhihan1996/DNABERT_hyphen_2_hyphen_117M/7bce263b15377fc15361f52cfab88f8b586abda0/flash_attn_triton.py\n",
            "\n",
            "🤖 加载训练好的模型...\n",
            "✅ 模型加载成功！设备: cuda\n",
            "✅ 前向传播测试通过！输出shape: torch.Size([1, 6, 4096])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Cell 3: 下载Shell et al. 2015数据\n",
        "\n",
        "# 这篇文章是：\n",
        "# Shell SS, et al. (2015) \"Leaderless Transcripts and Small Proteins Are Common Features of the Mycobacterial Translational Landscape\"\n",
        "# PLOS Genetics, DOI: 10.1371/journal.pgen.1005641\n",
        "\n",
        "# Supplementary数据在PLOS的网站上\n",
        "import requests\n",
        "import os\n",
        "\n",
        "print(\"📥 下载Shell et al. 2015 supplementary data...\")\n",
        "\n",
        "# PLOS Genetics的supplementary table通常是S1, S2等\n",
        "# 这篇文章的TSS数据在supplementary tables里\n",
        "\n",
        "# 先试着从NCBI GEO下载（这篇文章的数据在GEO: GSE62152）\n",
        "urls_to_try = [\n",
        "    # 论文的supplementary\n",
        "    \"https://doi.org/10.1371/journal.pgen.1005641.s008\",  # S1 Table\n",
        "    \"https://doi.org/10.1371/journal.pgen.1005641.s009\",  # S2 Table\n",
        "]\n",
        "\n",
        "print(\"尝试直接下载可能会被重定向，让我先搜索一下具体链接...\")\n",
        "\n",
        "# 显示你现有的文件\n",
        "print(\"\\n📁 你的MycoPromoter文件夹现有文件:\")\n",
        "myco_path = \"/content/drive/MyDrive/MycoPromoter/\"\n",
        "for f in os.listdir(myco_path):\n",
        "    print(f\"  {f}\")"
      ],
      "metadata": {
        "id": "GBa4JIXaDx1H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcc70fe7-9b13-4819-cce7-a06446eccd3a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📥 下载Shell et al. 2015 supplementary data...\n",
            "尝试直接下载可能会被重定向，让我先搜索一下具体链接...\n",
            "\n",
            "📁 你的MycoPromoter文件夹现有文件:\n",
            "  pretrain_corpus.txt\n",
            "  cached_lm_PreTrainedTokenizerFast_126_pretrain_corpus.txt\n",
            "  results\n",
            "  cached_lm_PreTrainedTokenizerFast_126_pretrain_corpus.txt.lock\n",
            "  dnabert2_mycobacterium\n",
            "  shell_2015_s2_table.xlsx\n",
            "  shell_2015_s1_table.xlsx\n",
            "  shell_2015_s3_table.xlsx\n",
            "  shell_2015_s4_table.xlsx\n",
            "  shell_promoters_with_seq.csv\n",
            "  train.csv\n",
            "  val.csv\n",
            "  test.csv\n",
            "  best_regression_model.pt\n",
            "  best_frozen_model.pt\n",
            "  mfe_distribution.png\n",
            "  all_features_correlation.png\n",
            "  cai_distribution.png\n",
            "  shell_denoised.csv\n",
            "  shell_classification.csv\n",
            "  ranking_pairs.pkl\n",
            "  best_ranking_model.pt\n",
            "  shell_with_predictions.csv\n",
            "  ranking_vs_expression.png\n",
            "  ranking_pairs_proper.pkl\n",
            "  test_set_heldout.csv\n",
            "  best_ranking_model_proper.pt\n",
            "  best_regression_model_proper.pt\n",
            "  msmeg_promoters.csv\n",
            "  shell2019_msmeg_promoters.csv\n",
            "  best_dnabert2_shell2019.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: 从PLOS Genetics下载Shell数据\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "print(\"📥 下载Shell et al. 2015 TSS数据...\")\n",
        "\n",
        "# Shell 2015的supplementary Excel文件\n",
        "# S2 Table包含TSS位置和表达量数据\n",
        "url = \"https://journals.plos.org/plosgenetics/article/file?type=supplementary&id=10.1371/journal.pgen.1005641.s009\"\n",
        "\n",
        "response = requests.get(url, allow_redirects=True)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    # 保存文件\n",
        "    save_path = \"/content/drive/MyDrive/MycoPromoter/shell_2015_s2_table.xlsx\"\n",
        "    with open(save_path, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "    print(f\"✅ 下载成功: {save_path}\")\n",
        "    print(f\"   文件大小: {len(response.content)/1024:.1f} KB\")\n",
        "\n",
        "    # 尝试读取\n",
        "    try:\n",
        "        df = pd.read_excel(save_path)\n",
        "        print(f\"\\n📊 数据预览:\")\n",
        "        print(f\"   行数: {len(df)}\")\n",
        "        print(f\"   列名: {list(df.columns)}\")\n",
        "        print(df.head())\n",
        "    except Exception as e:\n",
        "        print(f\"读取Excel失败: {e}\")\n",
        "        print(\"可能需要安装openpyxl: !pip install openpyxl\")\n",
        "else:\n",
        "    print(f\"❌ 下载失败: {response.status_code}\")\n",
        "    print(\"尝试备用方案...\")"
      ],
      "metadata": {
        "id": "GqJE_lgbEeI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69d4d793-511d-433b-b00c-488482ff35e6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📥 下载Shell et al. 2015 TSS数据...\n",
            "✅ 下载成功: /content/drive/MyDrive/MycoPromoter/shell_2015_s2_table.xlsx\n",
            "   文件大小: 47.6 KB\n",
            "\n",
            "📊 数据预览:\n",
            "   行数: 762\n",
            "   列名: [\"5' Ribo Boundary\", 'RTG codon position', 'Boundary to next RTG distance', 'Strand', 'LL or LD', 'Codon', 'Annotation', ' RTG relative to associated annotated gene']\n",
            "   5' Ribo Boundary  RTG codon position  Boundary to next RTG distance Strand  \\\n",
            "0              5633                5633                              0      +   \n",
            "1             59900               59900                              0      +   \n",
            "2             69734               69734                              0      -   \n",
            "3             76190               76190                              0      +   \n",
            "4            109849              109849                              0      -   \n",
            "\n",
            "     LL or LD Codon                                         Annotation  \\\n",
            "0  leaderless   ATG                                                NaN   \n",
            "1  leaderless   ATG  MSMEG_0042;  ; TetR-family transcriptional reg...   \n",
            "2  leaderless   ATG                MSMEG_0049;  ; pirin domain protein   \n",
            "3  leaderless   ATG                                                NaN   \n",
            "4  leaderless   ATG  MSMEG_0085;  ; PTS system, Fru family, IIABC c...   \n",
            "\n",
            "   RTG relative to associated annotated gene  \n",
            "0                                  Novel ORF  \n",
            "1                                  Annotated  \n",
            "2                                  Annotated  \n",
            "3                                  Novel ORF  \n",
            "4                                  Annotated  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
            "  warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: 下载包含表达量的数据表\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "print(\"📥 下载Shell 2015的表达量数据...\")\n",
        "\n",
        "# 尝试S1 Table（通常包含RPKM）\n",
        "urls = {\n",
        "    \"S1\": \"https://journals.plos.org/plosgenetics/article/file?type=supplementary&id=10.1371/journal.pgen.1005641.s008\",\n",
        "    \"S3\": \"https://journals.plos.org/plosgenetics/article/file?type=supplementary&id=10.1371/journal.pgen.1005641.s010\",\n",
        "    \"S4\": \"https://journals.plos.org/plosgenetics/article/file?type=supplementary&id=10.1371/journal.pgen.1005641.s011\",\n",
        "}\n",
        "\n",
        "for name, url in urls.items():\n",
        "    print(f\"\\n尝试下载 {name} Table...\")\n",
        "    response = requests.get(url, allow_redirects=True)\n",
        "\n",
        "    if response.status_code == 200 and len(response.content) > 1000:\n",
        "        save_path = f\"/content/drive/MyDrive/MycoPromoter/shell_2015_{name.lower()}_table.xlsx\"\n",
        "        with open(save_path, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "\n",
        "        try:\n",
        "            # 尝试读取所有sheet\n",
        "            xl = pd.ExcelFile(save_path)\n",
        "            print(f\"  ✅ {name}: {len(response.content)/1024:.1f} KB\")\n",
        "            print(f\"     Sheets: {xl.sheet_names}\")\n",
        "\n",
        "            # 读取第一个sheet看看列名\n",
        "            df = pd.read_excel(save_path, sheet_name=0)\n",
        "            print(f\"     列名: {list(df.columns)[:8]}...\")  # 只显示前8列\n",
        "\n",
        "            # 检查是否有RPKM相关的列\n",
        "            rpkm_cols = [c for c in df.columns if 'rpkm' in str(c).lower() or 'expression' in str(c).lower() or 'count' in str(c).lower()]\n",
        "            if rpkm_cols:\n",
        "                print(f\"     🎯 找到表达量相关列: {rpkm_cols}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  读取失败: {e}\")"
      ],
      "metadata": {
        "id": "QJXLZSi_E9nS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14303496-85d0-45fa-b806-845a16cb619a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📥 下载Shell 2015的表达量数据...\n",
            "\n",
            "尝试下载 S1 Table...\n",
            "  ✅ S1: 30.9 KB\n",
            "     Sheets: ['Msmeg LL transcripts']\n",
            "     列名: [\"5' RNA&Ribo Boundary\", 'RTG codon position', 'Stop position', 'Size', 'Strand', 'Codon', \"Dist 5' Boundary to RTG\", 'Annotation']...\n",
            "\n",
            "尝试下载 S3 Table...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
            "  warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ S3: 735.8 KB\n",
            "     Sheets: ['All TSSs', 'Leadered', 'Leaderless']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
            "  warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     列名: ['TSS unique identifier', 'Strand', 'Coordinate (genome version NC_000962)', 'Mean coverage in converted libraries', 'Downstream same-strand gene', 'position relative to downstream same-strand gene', 'Overlapping same-strand gene', 'Position in overlapping same-strand gene']...\n",
            "\n",
            "尝试下载 S4 Table...\n",
            "  ✅ S4: 70.2 KB\n",
            "     Sheets: ['acetyl or non-ATG met']\n",
            "     列名: ['orf', 'Unique identifier for strand/coord combo', 'strand', 'observed_orf', 'parent_orf', 'Coded aa', 'iCodon', 'Genome coordinate 1st nt of start codon']...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
            "  warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: 查看S3数据详情\n",
        "import pandas as pd\n",
        "\n",
        "s3_path = \"/content/drive/MyDrive/MycoPromoter/shell_2015_s3_table.xlsx\"\n",
        "\n",
        "# 读取All TSSs这个sheet\n",
        "df = pd.read_excel(s3_path, sheet_name=\"All TSSs\")\n",
        "\n",
        "print(f\"📊 S3 Table - All TSSs\")\n",
        "print(f\"行数: {len(df)}\")\n",
        "print(f\"\\n所有列名:\")\n",
        "for i, col in enumerate(df.columns):\n",
        "    print(f\"  {i+1}. {col}\")\n",
        "\n",
        "print(f\"\\n前5行数据:\")\n",
        "print(df.head())\n",
        "\n",
        "print(f\"\\n表达量列的统计:\")\n",
        "coverage_col = [c for c in df.columns if 'coverage' in c.lower() or 'mean' in c.lower()]\n",
        "if coverage_col:\n",
        "    print(df[coverage_col[0]].describe())"
      ],
      "metadata": {
        "id": "Qitjcba5FOYQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aef22030-2fcf-449d-c0db-8c35882caeee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 S3 Table - All TSSs\n",
            "行数: 4978\n",
            "\n",
            "所有列名:\n",
            "  1. TSS unique identifier\n",
            "  2. Strand\n",
            "  3. Coordinate (genome version NC_000962)\n",
            "  4. Mean coverage in converted libraries\n",
            "  5. Downstream same-strand gene\n",
            "  6. position relative to downstream same-strand gene\n",
            "  7. Overlapping same-strand gene\n",
            "  8. Position in overlapping same-strand gene\n",
            "  9. Position in overlapping same-strand gene relative to length\n",
            "  10. nt at +1\n",
            "\n",
            "前5行数据:\n",
            "  TSS unique identifier Strand  Coordinate (genome version NC_000962)  \\\n",
            "0              1776702+      +                                1776702   \n",
            "1               469591+      +                                 469591   \n",
            "2              2485273+      +                                2485273   \n",
            "3               645467+      +                                 645467   \n",
            "4              1160434-      -                                1160434   \n",
            "\n",
            "   Mean coverage in converted libraries Downstream same-strand gene  \\\n",
            "0                                  43.0                      Rv1570   \n",
            "1                                 106.5                      Rv0391   \n",
            "2                                 464.5                      Rv2219   \n",
            "3                                 182.0                      Rv0555   \n",
            "4                                  87.5                     Rv1036c   \n",
            "\n",
            "   position relative to downstream same-strand gene  \\\n",
            "0                                               NaN   \n",
            "1                                               NaN   \n",
            "2                                               NaN   \n",
            "3                                               NaN   \n",
            "4                                              -1.0   \n",
            "\n",
            "  Overlapping same-strand gene  Position in overlapping same-strand gene  \\\n",
            "0                       Rv1569                                       1.0   \n",
            "1                       Rv0390                                       1.0   \n",
            "2                       Rv2218                                       1.0   \n",
            "3                       Rv0554                                       1.0   \n",
            "4                         none                                       NaN   \n",
            "\n",
            "   Position in overlapping same-strand gene relative to length nt at +1  \n",
            "0                                                0.0                  A  \n",
            "1                                                0.0                  G  \n",
            "2                                                0.0                  A  \n",
            "3                                                0.0                  G  \n",
            "4                                                NaN                  G  \n",
            "\n",
            "表达量列的统计:\n",
            "count      4978.000000\n",
            "mean        251.340096\n",
            "std        1876.379632\n",
            "min          20.000000\n",
            "25%          35.500000\n",
            "50%          68.250000\n",
            "75%         165.875000\n",
            "max      120948.000000\n",
            "Name: Mean coverage in converted libraries, dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
            "  warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: 下载基因组 + 提取promoter序列\n",
        "!pip install biopython -q\n",
        "\n",
        "from Bio import Entrez, SeqIO\n",
        "import pandas as pd\n",
        "\n",
        "Entrez.email = \"student@example.com\"\n",
        "\n",
        "print(\"下载M. tuberculosis基因组...\")\n",
        "handle = Entrez.efetch(db=\"nucleotide\", id=\"NC_000962.3\", rettype=\"fasta\", retmode=\"text\")\n",
        "genome_record = SeqIO.read(handle, \"fasta\")\n",
        "handle.close()\n",
        "genome_seq = str(genome_record.seq)\n",
        "print(f\"基因组长度: {len(genome_seq)} bp\")\n",
        "\n",
        "df = pd.read_excel(\"/content/drive/MyDrive/MycoPromoter/shell_2015_s3_table.xlsx\", sheet_name=\"All TSSs\")\n",
        "print(f\"TSS数量: {len(df)}\")\n",
        "\n",
        "UPSTREAM = 150\n",
        "DOWNSTREAM = 50\n",
        "\n",
        "def extract_promoter(row, genome):\n",
        "    coord = int(row[\"Coordinate (genome version NC_000962)\"])\n",
        "    strand = row[\"Strand\"]\n",
        "    if strand == \"+\":\n",
        "        start = coord - UPSTREAM - 1\n",
        "        end = coord + DOWNSTREAM\n",
        "    else:\n",
        "        start = coord - DOWNSTREAM - 1\n",
        "        end = coord + UPSTREAM\n",
        "    start = max(0, start)\n",
        "    end = min(len(genome), end)\n",
        "    seq = genome[start:end]\n",
        "    if strand == \"-\":\n",
        "        comp = {\"A\":\"T\", \"T\":\"A\", \"G\":\"C\", \"C\":\"G\", \"N\":\"N\"}\n",
        "        seq = \"\".join(comp.get(b,\"N\") for b in reversed(seq))\n",
        "    return seq\n",
        "\n",
        "df[\"promoter_seq\"] = df.apply(lambda r: extract_promoter(r, genome_seq), axis=1)\n",
        "df[\"expression\"] = df[\"Mean coverage in converted libraries\"]\n",
        "\n",
        "print(\"完成!\")\n",
        "print(df[[\"expression\", \"promoter_seq\"]].head())\n",
        "\n",
        "df.to_csv(\"/content/drive/MyDrive/MycoPromoter/shell_promoters_with_seq.csv\", index=False)\n",
        "print(\"已保存!\")"
      ],
      "metadata": {
        "id": "4jGN5jlOGBJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee7028c5-6317-4d86-823d-00010e7fdb71"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m137.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h下载M. tuberculosis基因组...\n",
            "基因组长度: 4411532 bp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
            "  warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TSS数量: 4978\n",
            "完成!\n",
            "   expression                                       promoter_seq\n",
            "0        43.0  CGCGACTCCCGCGGCGCTGGATCGAGGCGTGTGGCTGCGCCCGTTT...\n",
            "1       106.5  GCTGACCGGTGCGCTCGGTGTGCCGGAAAGCGACGTCGTGATATTC...\n",
            "2       464.5  CGCCGCAGTGACATCGCTGTCCGCCGAACTCGGCCGTACGGTCACC...\n",
            "3       182.0  GCCCGCAGCACCCGTCGACGGCTTTCTGGCAGTTGCGCGGACAACG...\n",
            "4        87.5  TGGCACAAACCGACAGCGCCGTCGGCTCCAGCTGGGCCTAAAGCTG...\n",
            "已保存!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Stage 2 - 训练promoter强度预测模型\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "# 加载数据\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/MycoPromoter/shell_promoters_with_seq.csv\")\n",
        "print(f\"数据量: {len(df)}\")\n",
        "\n",
        "# 过滤掉太短的序列\n",
        "df = df[df[\"promoter_seq\"].str.len() >= 100]\n",
        "print(f\"过滤后: {len(df)}\")\n",
        "\n",
        "# Log转换表达量（因为范围很大：20 ~ 120948）\n",
        "df[\"log_expression\"] = np.log1p(df[\"expression\"])\n",
        "\n",
        "# 归一化到0-1\n",
        "min_val = df[\"log_expression\"].min()\n",
        "max_val = df[\"log_expression\"].max()\n",
        "df[\"normalized_expression\"] = (df[\"log_expression\"] - min_val) / (max_val - min_val)\n",
        "\n",
        "print(f\"表达量范围: {df['expression'].min():.1f} - {df['expression'].max():.1f}\")\n",
        "print(f\"归一化后: {df['normalized_expression'].min():.3f} - {df['normalized_expression'].max():.3f}\")\n",
        "\n",
        "# 划分训练集/验证集/测试集\n",
        "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"\\n训练集: {len(train_df)}, 验证集: {len(val_df)}, 测试集: {len(test_df)}\")\n",
        "\n",
        "# 保存划分\n",
        "train_df.to_csv(\"/content/drive/MyDrive/MycoPromoter/train.csv\", index=False)\n",
        "val_df.to_csv(\"/content/drive/MyDrive/MycoPromoter/val.csv\", index=False)\n",
        "test_df.to_csv(\"/content/drive/MyDrive/MycoPromoter/test.csv\", index=False)\n",
        "print(\"数据集已保存!\")"
      ],
      "metadata": {
        "id": "Yp1bIdByGRBQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "868a3c00-c5c3-4e39-c774-be4e2d1e569e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "数据量: 4978\n",
            "过滤后: 4978\n",
            "表达量范围: 20.0 - 120948.0\n",
            "归一化后: 0.000 - 1.000\n",
            "\n",
            "训练集: 3982, 验证集: 498, 测试集: 498\n",
            "数据集已保存!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: 定义Dataset和模型\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 加载tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
        "\n",
        "class PromoterDataset(Dataset):\n",
        "    def __init__(self, csv_path, tokenizer, max_length=128):\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        seq = row[\"promoter_seq\"]\n",
        "        label = row[\"normalized_expression\"]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            seq,\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
        "            \"label\": torch.tensor(label, dtype=torch.float)\n",
        "        }\n",
        "\n",
        "# 回归模型：DNABERT-2 + 回归头\n",
        "class PromoterStrengthModel(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super().__init__()\n",
        "        self.bert = base_model\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(768, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()  # 输出0-1\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        # 取[CLS] token的输出（序列的整体表示）\n",
        "        cls_output = outputs[0][:, 0, :]  # (batch, 768)\n",
        "        prediction = self.regressor(cls_output)\n",
        "        return prediction.squeeze()\n",
        "\n",
        "# 创建数据集\n",
        "train_dataset = PromoterDataset(\"/content/drive/MyDrive/MycoPromoter/train.csv\", tokenizer)\n",
        "val_dataset = PromoterDataset(\"/content/drive/MyDrive/MycoPromoter/val.csv\", tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "print(f\"训练集batches: {len(train_loader)}\")\n",
        "print(f\"验证集batches: {len(val_loader)}\")\n",
        "\n",
        "# 加载我们domain-adapted的DNABERT-2\n",
        "print(\"\\n加载模型...\")\n",
        "base_model = AutoModel.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
        "\n",
        "# 加载Stage 1训练的权重\n",
        "import torch\n",
        "state_dict = torch.load(\"/content/drive/MyDrive/MycoPromoter/dnabert2_mycobacterium/final/pytorch_model.bin\", weights_only=False)\n",
        "# 只加载bert部分的权重（忽略MLM head）\n",
        "bert_state_dict = {k.replace(\"bert.\", \"\"): v for k, v in state_dict.items() if k.startswith(\"bert.\")}\n",
        "base_model.load_state_dict(bert_state_dict, strict=False)\n",
        "\n",
        "model"
      ],
      "metadata": {
        "id": "zFDzWC9ZGgxl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f68b2f8b-435d-4388-d225-b1defa812f55"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "训练集batches: 249\n",
            "验证集batches: 32\n",
            "\n",
            "加载模型...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at zhihan1996/DNABERT-2-117M and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(4096, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertUnpadAttention(\n",
              "            (self): BertUnpadSelfAttention(\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (mlp): BertGatedLinearUnitMLP(\n",
              "            (gated_layers): Linear(in_features=768, out_features=6144, bias=False)\n",
              "            (act): GELU(approximate='none')\n",
              "            (wo): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (transform_act_fn): GELUActivation()\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=768, out_features=4096, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: 修复模型定义并重新训练\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from scipy.stats import spearmanr\n",
        "from transformers import AutoModel\n",
        "\n",
        "# 重新定义模型（修复版）\n",
        "class PromoterStrengthModel(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super().__init__()\n",
        "        # 直接加载base model，不是MLM model\n",
        "        self.bert = AutoModel.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
        "\n",
        "        # 加载domain-adapted权重\n",
        "        state_dict = torch.load(f\"{model_path}/pytorch_model.bin\", weights_only=False)\n",
        "        bert_state_dict = {k.replace(\"bert.\", \"\"): v for k, v in state_dict.items() if k.startswith(\"bert.\")}\n",
        "        self.bert.load_state_dict(bert_state_dict, strict=False)\n",
        "\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(768, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_output = outputs[0][:, 0, :]  # [CLS] token\n",
        "        prediction = self.regressor(cls_output)\n",
        "        return prediction.squeeze()\n",
        "\n",
        "# 创建新模型\n",
        "print(\"加载模型...\")\n",
        "model = PromoterStrengthModel(\"/content/drive/MyDrive/MycoPromoter/dnabert2_mycobacterium/final\")\n",
        "model = model.cuda()\n",
        "print(\"模型准备完成!\")\n",
        "\n",
        "# 训练配置\n",
        "EPOCHS = 10\n",
        "LR = 2e-5\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=0.01)\n",
        "\n",
        "print(f\"\\n开始训练... Epochs: {EPOCHS}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "best_spearman = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        input_ids = batch[\"input_ids\"].cuda()\n",
        "        attention_mask = batch[\"attention_mask\"].cuda()\n",
        "        labels = batch[\"label\"].cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # 验证\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch[\"input_ids\"].cuda()\n",
        "            attention_mask = batch[\"attention_mask\"].cuda()\n",
        "            labels = batch[\"label\"]\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            all_preds.extend(outputs.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    spearman = spearmanr(all_preds, all_labels)[0]\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {avg_loss:.4f} | Val Spearman: {spearman:.4f}\")\n",
        "\n",
        "    if spearman > best_spearman:\n",
        "        best_spearman = spearman\n",
        "        torch.save(model.state_dict(), \"/content/drive/MyDrive/MycoPromoter/best_regression_model.pt\")\n",
        "        print(f\"  -> 新最佳!\")\n",
        "\n",
        "print(f\"\\n训练完成! 最佳Spearman: {best_spearman:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Re6l7S9rHDy9",
        "outputId": "2131c829-00b5-4457-a0c0-e78cabc2c829"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "加载模型...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at zhihan1996/DNABERT-2-117M and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "模型准备完成!\n",
            "\n",
            "开始训练... Epochs: 10\n",
            "--------------------------------------------------\n",
            "Epoch 1/10 | Loss: 0.0244 | Val Spearman: 0.0525\n",
            "  -> 新最佳!\n",
            "Epoch 2/10 | Loss: 0.0163 | Val Spearman: 0.2881\n",
            "  -> 新最佳!\n",
            "Epoch 3/10 | Loss: 0.0149 | Val Spearman: 0.1886\n",
            "Epoch 4/10 | Loss: 0.0127 | Val Spearman: 0.2814\n",
            "Epoch 5/10 | Loss: 0.0103 | Val Spearman: 0.2614\n",
            "Epoch 6/10 | Loss: 0.0086 | Val Spearman: 0.3023\n",
            "  -> 新最佳!\n",
            "Epoch 7/10 | Loss: 0.0073 | Val Spearman: 0.2894\n",
            "Epoch 8/10 | Loss: 0.0065 | Val Spearman: 0.2780\n",
            "Epoch 9/10 | Loss: 0.0055 | Val Spearman: 0.2893\n",
            "Epoch 10/10 | Loss: 0.0048 | Val Spearman: 0.2737\n",
            "\n",
            "训练完成! 最佳Spearman: 0.3023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: 冻结BERT，重新训练\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from scipy.stats import spearmanr\n",
        "from transformers import AutoModel\n",
        "\n",
        "class PromoterStrengthModelFrozen(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super().__init__()\n",
        "        self.bert = AutoModel.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
        "\n",
        "        # 加载domain-adapted权重\n",
        "        state_dict = torch.load(f\"{model_path}/pytorch_model.bin\", weights_only=False)\n",
        "        bert_state_dict = {k.replace(\"bert.\", \"\"): v for k, v in state_dict.items() if k.startswith(\"bert.\")}\n",
        "        self.bert.load_state_dict(bert_state_dict, strict=False)\n",
        "\n",
        "        # 冻结BERT所有参数！\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # 更大的回归头\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(768, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        with torch.no_grad():  # BERT不计算梯度\n",
        "            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_output = outputs[0][:, 0, :]\n",
        "        prediction = self.regressor(cls_output)\n",
        "        return prediction.squeeze()\n",
        "\n",
        "# 创建新模型\n",
        "print(\"加载模型（BERT冻结版）...\")\n",
        "model = PromoterStrengthModelFrozen(\"/content/drive/MyDrive/MycoPromoter/dnabert2_mycobacterium/final\")\n",
        "model = model.cuda()\n",
        "\n",
        "# 只有回归头的参数会被训练\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"可训练参数: {trainable_params:,} / {total_params:,}\")\n",
        "\n",
        "# 训练配置 - 更大的学习率（因为只训练回归头）\n",
        "EPOCHS = 30\n",
        "LR = 1e-3\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LR)\n",
        "\n",
        "print(f\"\\n开始训练... Epochs: {EPOCHS}, LR: {LR}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "best_spearman = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        input_ids = batch[\"input_ids\"].cuda()\n",
        "        attention_mask = batch[\"attention_mask\"].cuda()\n",
        "        labels = batch[\"label\"].cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # 验证\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch[\"input_ids\"].cuda()\n",
        "            attention_mask = batch[\"attention_mask\"].cuda()\n",
        "            labels = batch[\"label\"]\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            all_preds.extend(outputs.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    spearman = spearmanr(all_preds, all_labels)[0]\n",
        "\n",
        "    # 每5个epoch打印一次，或者有新最佳时打印\n",
        "    if (epoch + 1) % 5 == 0 or spearman > best_spearman:\n",
        "        print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {avg_loss:.4f} | Val Spearman: {spearman:.4f}\")\n",
        "\n",
        "    if spearman > best_spearman:\n",
        "        best_spearman = spearman\n",
        "        torch.save(model.state_dict(), \"/content/drive/MyDrive/MycoPromoter/best_frozen_model.pt\")\n",
        "        print(f\"  -> 新最佳!\")\n",
        "\n",
        "print(f\"\\n训练完成! 最佳Spearman: {best_spearman:.4f}\")"
      ],
      "metadata": {
        "id": "EOAj2DlXK5xt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7db88903-ec34-4ac5-815d-53abd4b383f8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "加载模型（BERT冻结版）...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at zhihan1996/DNABERT-2-117M and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "可训练参数: 459,521 / 117,528,065\n",
            "\n",
            "开始训练... Epochs: 30, LR: 0.001\n",
            "--------------------------------------------------\n",
            "Epoch 1/30 | Loss: 0.0188 | Val Spearman: 0.2738\n",
            "  -> 新最佳!\n",
            "Epoch 3/30 | Loss: 0.0167 | Val Spearman: 0.2852\n",
            "  -> 新最佳!\n",
            "Epoch 5/30 | Loss: 0.0163 | Val Spearman: 0.2924\n",
            "  -> 新最佳!\n",
            "Epoch 10/30 | Loss: 0.0155 | Val Spearman: 0.2553\n",
            "Epoch 15/30 | Loss: 0.0150 | Val Spearman: 0.2418\n",
            "Epoch 20/30 | Loss: 0.0139 | Val Spearman: 0.2233\n",
            "Epoch 25/30 | Loss: 0.0131 | Val Spearman: 0.2133\n",
            "Epoch 30/30 | Loss: 0.0123 | Val Spearman: 0.2122\n",
            "\n",
            "训练完成! 最佳Spearman: 0.2924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.bert)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsHdOfIYs8wT",
        "outputId": "8b3b2cd0-6f4c-45c9-a49c-c3173097b237"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(4096, 768)\n",
            "    (token_type_embeddings): Embedding(2, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0-11): 12 x BertLayer(\n",
            "        (attention): BertUnpadAttention(\n",
            "          (self): BertUnpadSelfAttention(\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (mlp): BertGatedLinearUnitMLP(\n",
            "          (gated_layers): Linear(in_features=768, out_features=6144, bias=False)\n",
            "          (act): GELU(approximate='none')\n",
            "          (wo): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: LoRA + 生物学特征\n",
        "\n",
        "!pip install peft -q  # LoRA库\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import re\n",
        "import numpy as np\n",
        "from scipy.stats import spearmanr\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "# ============ 生物学特征提取 ============\n",
        "\n",
        "def extract_bio_features(seq):\n",
        "    \"\"\"从序列中提取生物学特征\"\"\"\n",
        "    features = []\n",
        "\n",
        "    # 1. GC含量\n",
        "    gc = (seq.count('G') + seq.count('C')) / len(seq)\n",
        "    features.append(gc)\n",
        "\n",
        "    # 2. -10区 motif匹配 (TATAAT)，检查位置130-150\n",
        "    minus10_region = seq[130:150] if len(seq) >= 150 else seq[-50:-30]\n",
        "    minus10_consensus = \"TATAAT\"\n",
        "    best_minus10_score = 0\n",
        "    for i in range(len(minus10_region) - 6):\n",
        "        score = sum(a == b for a, b in zip(minus10_region[i:i+6], minus10_consensus))\n",
        "        best_minus10_score = max(best_minus10_score, score)\n",
        "    features.append(best_minus10_score / 6)  # 归一化到0-1\n",
        "\n",
        "    # 3. -35区 motif匹配 (TTGACA)，检查位置110-130\n",
        "    minus35_region = seq[110:130] if len(seq) >= 130 else seq[-70:-50]\n",
        "    minus35_consensus = \"TTGACA\"\n",
        "    best_minus35_score = 0\n",
        "    for i in range(len(minus35_region) - 6):\n",
        "        score = sum(a == b for a, b in zip(minus35_region[i:i+6], minus35_consensus))\n",
        "        best_minus35_score = max(best_minus35_score, score)\n",
        "    features.append(best_minus35_score / 6)\n",
        "\n",
        "    # 4. AT含量在-10区附近（AT-rich有助于DNA解链）\n",
        "    if len(seq) >= 150:\n",
        "        at_region = seq[125:155]\n",
        "        at_content = (at_region.count('A') + at_region.count('T')) / len(at_region)\n",
        "    else:\n",
        "        at_content = (seq.count('A') + seq.count('T')) / len(seq)\n",
        "    features.append(at_content)\n",
        "\n",
        "    # 5. 简单重复序列比例qkv\n",
        "    repeats = len(re.findall(r'(.)\\1{2,}', seq))\n",
        "    features.append(min(repeats / 10, 1.0))\n",
        "\n",
        "    return features\n",
        "\n",
        "# 测试特征提取\n",
        "test_seq = \"ACGT\" * 50\n",
        "print(f\"特征示例: {extract_bio_features(test_seq)}\")\n",
        "print(f\"特征含义: [GC含量, -10区匹配, -35区匹配, AT含量, 重复序列]\")\n",
        "\n",
        "# ============ 带生物特征的Dataset ============\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "\n",
        "class PromoterDatasetWithFeatures(Dataset):\n",
        "    def __init__(self, csv_path, tokenizer, max_length=128):\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        seq = row[\"promoter_seq\"]\n",
        "        label = row[\"normalized_expression\"]\n",
        "\n",
        "        # Tokenize\n",
        "        encoding = self.tokenizer(\n",
        "            seq, truncation=True, max_length=self.max_length,\n",
        "            padding=\"max_length\", return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # 生物学特征\n",
        "        bio_features = torch.tensor(extract_bio_features(seq), dtype=torch.float)\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
        "            \"bio_features\": bio_features,\n",
        "            \"label\": torch.tensor(label, dtype=torch.float)\n",
        "        }\n",
        "\n",
        "# ============ LoRA + 生物特征 模型 ============\n",
        "\n",
        "class PromoterModelLoRA(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super().__init__()\n",
        "\n",
        "        # 加载BERT\n",
        "        self.bert = AutoModel.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
        "\n",
        "        # 加载domain-adapted权重\n",
        "        state_dict = torch.load(f\"{model_path}/pytorch_model.bin\", weights_only=False)\n",
        "        bert_state_dict = {k.replace(\"bert.\", \"\"): v for k, v in state_dict.items() if k.startswith(\"bert.\")}\n",
        "        self.bert.load_state_dict(bert_state_dict, strict=False)\n",
        "\n",
        "        # 添加LoRA\n",
        "        lora_config = LoraConfig(\n",
        "            r=8,                      # LoRA秩，越小参数越少\n",
        "            lora_alpha=16,            # 缩放因子\n",
        "            target_modules=[\"Wqkv\"],  # 只在attention层加LoRA\n",
        "            lora_dropout=0.1,\n",
        "            bias=\"none\"\n",
        "        )\n",
        "        self.bert = get_peft_model(self.bert, lora_config)\n",
        "\n",
        "        # 回归头：BERT输出(768) + 生物特征(5) = 773\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(768 + 5, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, bio_features):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_output = outputs[0][:, 0, :]  # [CLS] token: (batch, 768)\n",
        "\n",
        "        # 拼接BERT输出和生物特征\n",
        "        combined = torch.cat([cls_output, bio_features], dim=1)  # (batch, 773)\n",
        "\n",
        "        prediction = self.regressor(combined)\n",
        "        return prediction.squeeze()\n",
        "\n",
        "# ============ 准备数据 ============\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
        "\n",
        "train_dataset = PromoterDatasetWithFeatures(\"/content/drive/MyDrive/MycoPromoter/train.csv\", tokenizer)\n",
        "val_dataset = PromoterDatasetWithFeatures(\"/content/drive/MyDrive/MycoPromoter/val.csv\", tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "print(f\"\\n数据集: 训练{len(train_dataset)}, 验证{len(val_dataset)}\")\n",
        "\n",
        "# ============ 创建模型 ============\n",
        "\n",
        "print(\"\\n加载LoRA模型...\")\n",
        "model = PromoterModelLoRA(\"/content/drive/MyDrive/MycoPromoter/dnabert2_mycobacterium/final\")\n",
        "model = model.cuda()\n",
        "\n",
        "# 打印可训练参数\n",
        "model.bert.print_trainable_parameters()\n",
        "\n",
        "# ============ 训练 ============\n",
        "\n",
        "EPOCHS = 20\n",
        "LR = 5e-4\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=0.01)\n",
        "\n",
        "print(f\"\\n开始训练... Epochs: {EPOCHS}, LR: {LR}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "best_spearman = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        input_ids = batch[\"input_ids\"].cuda()\n",
        "        attention_mask = batch[\"attention_mask\"].cuda()\n",
        "        bio_features = batch[\"bio_features\"].cuda()\n",
        "        labels = batch[\"label\"].cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask, bio_features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # 验证\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch[\"input_ids\"].cuda()\n",
        "            attention_mask = batch[\"attention_mask\"].cuda()\n",
        "            bio_features = batch[\"bio_features\"].cuda()\n",
        "            labels = batch[\"label\"]\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, bio_features)\n",
        "            all_preds.extend(outputs.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    spearman = spearmanr(all_preds, all_labels)[0]\n",
        "\n",
        "    if (epoch + 1) % 5 == 0 or spearman > best_spearman:\n",
        "        print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {avg_loss:.4f} | Val Spearman: {spearman:.4f}\")\n",
        "\n",
        "    if spearman > best_spearman:\n",
        "        best_spearman = spearman\n",
        "        torch.save(model.state_dict(), \"/content/drive/MyDrive/MycoPromoter/best_lora_model.pt\")\n",
        "        print(f\"  -> 新最佳!\")\n",
        "\n",
        "print(f\"\\n训练完成! 最佳Spearman: {best_spearman:.4f}\")"
      ],
      "metadata": {
        "id": "p7rUlg03SFUl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d998c4eb-693c-4e27-e556-d0f0b962b66e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "特征示例: [0.5, 0.3333333333333333, 0.3333333333333333, 0.4666666666666667, 0.0]\n",
            "特征含义: [GC含量, -10区匹配, -35区匹配, AT含量, 重复序列]\n",
            "\n",
            "数据集: 训练3982, 验证498\n",
            "\n",
            "加载LoRA模型...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at zhihan1996/DNABERT-2-117M and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 294,912 || all params: 117,363,456 || trainable%: 0.2513\n",
            "\n",
            "开始训练... Epochs: 20, LR: 0.0005\n",
            "--------------------------------------------------\n",
            "Epoch 1/20 | Loss: 0.0219 | Val Spearman: 0.2702\n",
            "  -> 新最佳!\n",
            "Epoch 2/20 | Loss: 0.0175 | Val Spearman: 0.2979\n",
            "  -> 新最佳!\n",
            "Epoch 4/20 | Loss: 0.0163 | Val Spearman: 0.2983\n",
            "  -> 新最佳!\n",
            "Epoch 5/20 | Loss: 0.0153 | Val Spearman: 0.3027\n",
            "  -> 新最佳!\n",
            "Epoch 10/20 | Loss: 0.0101 | Val Spearman: 0.2523\n",
            "Epoch 15/20 | Loss: 0.0074 | Val Spearman: 0.2597\n",
            "Epoch 20/20 | Loss: 0.0059 | Val Spearman: 0.2522\n",
            "\n",
            "训练完成! 最佳Spearman: 0.3027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: 测试训练后的模型（修复版）\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/MycoPromoter/dnabert2_mycobacterium/final\"\n",
        "\n",
        "print(\"🔄 加载训练后的模型...\")\n",
        "\n",
        "# 先检查保存了什么文件\n",
        "import os\n",
        "print(\"保存的文件:\")\n",
        "for f in os.listdir(MODEL_PATH):\n",
        "    print(f\"  {f}\")\n",
        "\n",
        "# tokenizer用原版的，模型用训练后的\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
        "\n",
        "# 加载本地模型权重\n",
        "model = AutoModelForMaskedLM.from_pretrained(\n",
        "    \"zhihan1996/DNABERT-2-117M\",  # 用原版配置\n",
        "    trust_remote_code=True\n",
        ")\n",
        "# 加载我们训练的权重\n",
        "import torch\n",
        "state_dict = torch.load(f\"{MODEL_PATH}/pytorch_model.bin\", weights_only=False)\n",
        "model.load_state_dict(state_dict)\n",
        "model = model.cuda()\n",
        "model.eval()\n",
        "\n",
        "print(\"✅ 模型加载成功！\")\n",
        "\n",
        "# 测试\n",
        "test_seq = \"ACGT\" + tokenizer.mask_token + \"ACGT\"\n",
        "inputs = tokenizer(test_seq, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "mask_idx = (inputs.input_ids == tokenizer.mask_token_id).nonzero(as_tuple=True)[1]\n",
        "logits = outputs.logits[0, mask_idx[0]]\n",
        "top5 = torch.topk(logits, 5)\n",
        "\n",
        "print(f\"\\n🧪 测试输入: {test_seq}\")\n",
        "print(\"Top 5 预测:\")\n",
        "for i, (score, idx) in enumerate(zip(top5.values, top5.indices)):\n",
        "    token = tokenizer.decode([idx])\n",
        "    print(f\"  {i+1}. '{token}' (score: {score:.2f})\")"
      ],
      "metadata": {
        "id": "J7H0eeVratYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09077f8b-4465-46bb-bd6a-9446e2b16b74"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 加载训练后的模型...\n",
            "保存的文件:\n",
            "  configuration_bert.py\n",
            "  config.json\n",
            "  generation_config.json\n",
            "  pytorch_model.bin\n",
            "  tokenizer_config.json\n",
            "  special_tokens_map.json\n",
            "  tokenizer.json\n",
            "✅ 模型加载成功！\n",
            "\n",
            "🧪 测试输入: ACGT[MASK]ACGT\n",
            "Top 5 预测:\n",
            "  1. 'GGCCA' (score: 2.97)\n",
            "  2. 'GTC' (score: 2.96)\n",
            "  3. 'GGCC' (score: 2.69)\n",
            "  4. 'GTCC' (score: 2.60)\n",
            "  5. 'GGTG' (score: 2.53)\n"
          ]
        }
      ]
    }
  ]
}